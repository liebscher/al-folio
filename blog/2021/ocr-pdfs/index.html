<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Alex  Liebscher | Open Source OCR'ing PDF Documents in Python</title>
<meta name="description" content="A home for Alex Liebscher, featuring news, a blog, projects, and publications
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2021/ocr-pdfs/">

<!-- Theming-->




    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Open Source OCR'ing PDF Documents in Python",
      "description": "an introduction to OCR using high quality open source software",
      "published": "2021-02-23 00:00:00 -0800",
      "readtime": "7",
      "authors": [
        
        {
          "author": "A.L.",
          "authorURL": "",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Alex</span>   Liebscher
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/resources/">
                resources
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Open Source OCR'ing PDF Documents in Python</h1>
        <p>an introduction to OCR using high quality open source software</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <h1 id="overview">Overview</h1>

<p>Despite our recent <a href="https://business.linkedin.com/talent-solutions/blog/trends-and-research/2020/global-data-shows-surge-in-remote-work">global shift toward digital communication</a>, there are still reasons we might come across scanned documents in our every day life. Scanned documents don’t inherently come with searchable or copy-able text embedded within. More often, they’re basically just images. It can be useful to extract the text from these documents though, whether for record keeping or simply organization. Manually transcribing documents is tedious, especially if there are more than about a handful.</p>

<p>This is where Optical Character Recognition (OCR) is useful. We can start with a document, then process that document to not only extract the text on the page, but overlay the text on the document for readability and convenience later on. Most documents we face this kind of problem with are PDFs, a near ubiquitous format by now, hence our focus on tackling OCR with PDFs.</p>

<p>In this short article, I’ll run us through an introduction to OCR for PDF documents in Python, with a focus on using Open Source Software (OSS).</p>

<h1 id="whats-a-pdf">What’s a PDF?</h1>

<p>First, a <a href="https://en.wikipedia.org/wiki/PDF">Portable Document Format (PDF)</a> is a file which presents information, including text, images, forms, interactive content, and more. PDFs contain 7-bit ASCII characters, so opening one in a text editor will show you mostly a garble of characters you’ve never seen before. This is all in the <a href="http://jimpravetz.com/blog/2012/12/in-defense-of-cos/">Carousel Object Structure</a>, which is almost like a predecessor to XML and JSON. However, what comes off like a mess is actually a detailed layout of the document, including layers with all the text within the document, complex data structures, and embedded images.</p>

<h1 id="introduction-to-tesseract">Introduction to Tesseract</h1>

<p>OCR has a history dating back to the early 1900s, whose progress has picked up pace during the 60s and 70s and has made an occasional jump forward in the last couple decades. Because it is a well known problem, many initiatives have made progress in accuracy, and one in particular is <a href="https://www.hitechnectar.com/blogs/open-source-ocr-tools/">widely acclaimed</a>. This is <a href="https://tesseract-ocr.github.io/">Tesseract OCR</a>.</p>

<p>Tesseract is an open source OCR engine with more than 100 recognized languages, and a number of useful output types (another image, text, PDF, etc). It is moderately configurable, but has a large following and maintainer community. Most importantly though, in general it works well.</p>

<p>While there are APIs that layer on top of Tesseract, the engine itself is largely written in C++ and used through a command line interface. The engine accepts as input an image, and if it recognizes text within the image, it will attempt to classify the letters and words in the image and then output the transcription.</p>

<div class="row mt-3 justify-content-center">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid z-depth-1" src="/assets/img/bus-example.png" />
    </div>
</div>
<div class="caption">
  Figure 1. An example of OCR with Tesseract from the original image to the text output.
</div>

<p>For example, in the above figure, we see how after cropping an image of a bus to retain mostly just the text, we can run Tesseract which outputs the text in the image.</p>

<p>This is the essence of Tesseract. Its simplicity, efficiency, and accuracy make it an ideal solution for targeted (i.e. minimal content surrounding the text) and fairly readable (i.e. success not guaranteed on Captchas) <em>images</em>.</p>

<h1 id="introduction-to-ocrmypdf">Introduction to OCRmyPDF</h1>

<p>Tesseract works great for images, but as discussed above, most documents come as PDFs, and PDFs are a sophisticated data structure. Tesseract does allow the <em>output</em> of PDFs, but one cannot <em>input</em> a PDF to Tesseract. While we could hack our way around PDFs to apply Tesseract on them, there exists an open source solution which I’ve recently worked with and found useful.</p>

<p>Namely, <a href="https://ocrmypdf.readthedocs.io/en/latest/">OCRmyPDF</a> is a specialized command line tool and Python package which is built on a Tesseract OCR engine. OCRmyPDF does accept PDFs as input, and can not only output the text as a companion (<em>sidecar</em>) text file, but also overlays the text directly on top of the underlying images in the PDF. OCRmyPDF essentially pulls out the bitmap images from the PDF, performs a series of pre-processing steps (e.g. denoising, deskewing, etc.), then performs OCR on those images.</p>

<p>Suppose we have a PDF which looks like the following:</p>

<embed src="/assets/pdf/propublica-tax.pdf" height="500" type="application/pdf" style="margin:2em 0;" />

<p>Yes, I chose the 2018 tax returns of <a href="https://www.propublica.org/">ProPublica</a>. They’re always investigating people, I think it’s only fair we investigate them too. Besides saving only the most interesting pages in the full 65 page IRS report, I didn’t alter the document at all. You’ll notice you can’t select any of the text in the document though!</p>

<p>OCRmyPDF to the rescue. If we save this document, and in the working folder run the following Bash command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ocrmypdf propublica-tax.pdf propublica-tax-out.pdf --sidecar propublica-tax.txt
</code></pre></div></div>

<p>the package will process the original PDF (the first argument), then output the OCR’d PDF to the output file (second argument), and will also output a text file with the extracted text (file provided by the <code class="language-plaintext highlighter-rouge">--sidecar</code> flag). Here is the OCR’d file:</p>

<embed src="/assets/pdf/propublica-tax-out.pdf" height="500" type="application/pdf" style="margin:2em 0;" />

<p>While I encourage you to highlight and select text within the document, for those of you on mobile, here is a sample of what’s in the text file:</p>

<blockquote>
  <p>A For the 2019 calendar year, or tax year beginning 01-01-2018 , and ending 12-31-2018</p>

  <p>B Check if applicable</p>

  <p>OO Address change</p>

  <p>O Name change</p>

  <p>Return of Organization Exempt From Income Tax</p>

  <p>Under section 501(c), 527, or 4947(a)(1) of the Internal Revenue Code (except private foundations)</p>

  <p>® Do not enter social security numbers on this form as it may be made public</p>

  <p>» Go to www.irs.gov/Form990 for instructions and the latest information.</p>

  <p>OMB No 1545-0047</p>

  <p>2018</p>

  <p>Open to Public</p>

  <p>Inspection</p>

  <p>C Name of organization</p>

  <p>PRO PUBLICA INC</p>

  <p>D Employer identification number</p>

  <p>14-2007220</p>
</blockquote>

<p>Clearly, it has flaws. Namely, it’s fairly poor at disambiguating table and cell structures, and special characters are difficult to interpret. It gets some structure correct, but there’s only so much formatting we can represent with plain text files. Overall though, we could do a lot of processing with this text data. Across many tax returns, I’m sure we’d notice plenty of patterns and extracting the most useful information would not be that difficult.</p>

<h1 id="concurrent-processing-of-pdfs">Concurrent Processing of PDFs</h1>

<p>OCRmyPDF may work very well in this way should you have only a handful of PDFs to process. If you have dozens, hundreds, or millions of PDFs, this process would take too long. One way to make this more efficient is to use multiprocessing, or concurrency.</p>

<p>We can do this with a little Python, although I’ve recently looked into learning some Go since I hear that concurrency is natively supported with their syntax and functions very well (see <a href="https://divan.dev/posts/go_concurrency_visualize/">this cool concurrency visualization</a> using Go).</p>

<p>Using the <code class="language-plaintext highlighter-rouge">multiprocessing</code> native library in Python, roughly, we can spin up multiple processes (spread across however many CPUs you have) that each control an OCR job in parallel. If you have $N$ processes, and they’ll all able to run in parallel, the time to run the total task will be divided by $N$. If you have 100 PDFs, and each takes 20 seconds to OCR, this would take 30 minutes in serial—in parallel on 4 processes, this would take (surprise), 8.3 minutes.</p>

<p>To make a small script to OCR many local documents, it would: first, load the names of the files to process. Second, distribute those files to parallel jobs. Third, execute each job. All of this can be executed in essentially less than 10 lines of code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>
<span class="kn">import</span> <span class="nn">ocrmypdf</span>

<span class="n">PROCESSES</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="n">scandir</span><span class="p">(</span><span class="s">'pdfs/'</span><span class="p">)]</span>

<span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">)</span> <span class="o">/</span> <span class="n">PROCESSES</span><span class="p">)</span>
<span class="n">file_chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">files</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">ocr_files</span><span class="p">(</span><span class="n">file_list</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">input_file</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
        <span class="n">ocrmypdf</span><span class="p">.</span><span class="n">ocr</span><span class="p">(</span><span class="s">"pdfs/"</span> <span class="o">+</span> <span class="n">input_file</span><span class="p">,</span> <span class="s">"pdfs/out_"</span> <span class="o">+</span> <span class="n">input_file</span><span class="p">)</span>

<span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">PROCESSES</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
    <span class="n">pool</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">ocr_files</span><span class="p">,</span> <span class="n">file_chunks</span><span class="p">)</span>
</code></pre></div></div>

<p>To break this down a little:</p>

<ol>
  <li>We predefine the number of CPU processes to spawn. This number can be static, or reflect the machine being used (i.e. <code class="language-plaintext highlighter-rouge">os.cpu_count()</code>).</li>
  <li>Find the documents to process (in the <code class="language-plaintext highlighter-rouge">pdfs/</code> directory). Take this list of files and group it into evenly sized chunks.</li>
  <li>Create a small helper function to iterate over the files given to the process. Here is where we call the OCRmyPDF API.</li>
  <li>Create a process pool with $N$ processes, and map the chunks of files over the helper function.</li>
</ol>

<p>There are numerous improvements we could make, but this is a start. We’re not catching exceptions, we’re not allowing processes to recover if they face an error and shut down, we’re not logging, we’re not properly creating file paths (i.e. using <code class="language-plaintext highlighter-rouge">os.path.join</code>), etc.</p>

<p>However, this would OCR a decent sized batch of PDFs for the lay person. Hopefully this tutorial is useful to those looking to dip their feet into OCR with Python without spending excessive amounts of time or money on cloud compute or proprietary software. My final comment and question for the reader: what is the best way to say, in verb form, that one will “OCR” a document (to Optical Character Recognize sounds awful)?</p>

<p>If you have any questions or would like (me) to clarify anything, please <a href="mailto:alexliebscher0@gmail.com">let me know</a>!</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Alex  Liebscher.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: March 01, 2021.
    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/">
  </d-bibliography>

  

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>

<!-- GoatCounter Analytics -->
<script data-goatcounter="https://liebscher.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>


</html>
